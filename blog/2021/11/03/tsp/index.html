<!doctype html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-alpha.70">
<link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Eki.Lab Blog RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Eki.Lab Blog Atom Feed">
<link rel="preconnect" href="https://www.google-analytics.com">
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-124520099-9","auto"),ga("set","anonymizeIp",!0),ga("send","pageview")</script>
<script async src="https://www.google-analytics.com/analytics.js"></script><title data-react-helmet="true">Solving the Traveling Salesman Problem with Reinforcement Learning | Eki.Lab</title><meta data-react-helmet="true" property="og:title" content="Solving the Traveling Salesman Problem with Reinforcement Learning | Eki.Lab"><meta data-react-helmet="true" name="description" content="A practical use of Reinforcement Learning and the Q-Learning algorithm to solve the Traveling Salesman Problem"><meta data-react-helmet="true" property="og:description" content="A practical use of Reinforcement Learning and the Q-Learning algorithm to solve the Traveling Salesman Problem"><meta data-react-helmet="true" property="og:image" content="http://ekimetrics.github.io/img/10-cubecube03.jpg"><meta data-react-helmet="true" name="twitter:image" content="http://ekimetrics.github.io/img/10-cubecube03.jpg"><meta data-react-helmet="true" name="twitter:image:alt" content="Image for Solving the Traveling Salesman Problem with Reinforcement Learning | Eki.Lab"><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_tag" content="default"><meta data-react-helmet="true" name="keywords" content="Data Science,EkiLab,Ekimetrics,Eki.Lab,Eki,Machine Learning,Artificial Intelligence,Reinforcement Learning,Logistics,Supply Chain,Data Science for business"><link data-react-helmet="true" rel="shortcut icon" href="/img/favicon.png"><link rel="stylesheet" href="/styles.d3328ef8.css">
<link rel="preload" href="/styles.e35008ef.js" as="script">
<link rel="preload" href="/runtime~main.9e97a696.js" as="script">
<link rel="preload" href="/main.792963b8.js" as="script">
<link rel="preload" href="/1.11b8b369.js" as="script">
<link rel="preload" href="/2.2d4efa6a.js" as="script">
<link rel="preload" href="/108.db740e28.js" as="script">
<link rel="preload" href="/01a85c17.cf0f7590.js" as="script">
<link rel="preload" href="/1be78505.a54828de.js" as="script">
<link rel="preload" href="/6442c0a2.954850d5.js" as="script">
<link rel="preload" href="/6875c492.91e21155.js" as="script">
<link rel="preload" href="/a6aa9e1f.8f6293d7.js" as="script">
<link rel="preload" href="/bb9d1367.6cb11fe8.js" as="script">
<link rel="preload" href="/ccc49370.d52064ed.js" as="script">
<link rel="preload" href="/db8a5f2c.32a992fa.js" as="script">
<link rel="preload" href="/111.e6761f52.js" as="script">
<link rel="preload" href="/ece8ad2d.23c964c5.js" as="script">
<link rel="preload" href="/c4f5d8e4.904556d1.js" as="script">
<link rel="preload" href="/2e4ccabb.01f0e56c.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}()</script><div id="__docusaurus">
<nav aria-label="Skip navigation links"><button type="button" tabindex="0" class="skipToContent_11B0">Skip to main content</button></nav><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><div aria-label="Navigation bar toggle" class="navbar__toggle" role="button" tabindex="0"><svg aria-label="Menu" width="30" height="30" viewBox="0 0 30 30" role="img" focusable="false"><title>Menu</title><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></div><a class="navbar__brand" href="/"><strong class="navbar__title">Eki.Lab</strong></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/trainings/">Trainings</a><a class="navbar__item navbar__link" href="/docs/">Best practices</a><a class="navbar__item navbar__link" href="/hacks/">Hackathons</a><a class="navbar__item navbar__link" href="/opensource/">Open Source</a></div><div class="navbar__items navbar__items--right"><a href="https://ekimetrics.com/fr/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Ekimetrics website</a><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Contact us!</a><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input type="search" id="search_input_react" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div><div class="navbar-sidebar"><div class="navbar-sidebar__brand"><a class="navbar__brand" href="/"><strong class="navbar__title">Eki.Lab</strong></a></div><div class="navbar-sidebar__items"><div class="menu"><ul class="menu__list"><li class="menu__list-item"><a aria-current="page" class="menu__link navbar__link--active" href="/blog">Blog</a></li><li class="menu__list-item"><a class="menu__link" href="/trainings/">Trainings</a></li><li class="menu__list-item"><a class="menu__link" href="/docs/">Best practices</a></li><li class="menu__list-item"><a class="menu__link" href="/hacks/">Hackathons</a></li><li class="menu__list-item"><a class="menu__link" href="/opensource/">Open Source</a></li><li class="menu__list-item"><a href="https://ekimetrics.com/fr/" target="_blank" rel="noopener noreferrer" class="menu__link">Ekimetrics website</a></li><li class="menu__list-item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="menu__link">Contact us!</a></li></ul></div></div></div></nav><div class="main-wrapper blog-wrapper"><div class="container container-wide margin-vert--lg"><div class="row"><div class="col col--2"></div><main class="col col--8"><article><header><h1 class="margin-bottom--sm blogPostTitle_kDB-">Solving the Traveling Salesman Problem with Reinforcement Learning</h1><div class="margin-vert--md"><p>A practical use of Reinforcement Learning and the Q-Learning algorithm to solve the Traveling Salesman Problem</p><time datetime="2021-11-03T00:00:00.000Z" class="blogPostDate_2HVl">November 3, 2021  · 14 min read</time></div><div class="avatar margin-vert--md"><div class="avatar__intro"><h4 class="avatar__name">Written by <a href="mailto:inno@ekimetrics.com" target="_blank" rel="noreferrer noopener">Théo Alves Da Costa</a></h4><small class="avatar__subtitle"></small></div></div><div class="margin-vert--md"><img class="img-blog-header" src="/img/blog/tsp.jfif"></div></header><section class="markdown blog-article-custom"><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="summary"></a>Summary<a class="hash-link" href="#summary" title="Direct link to heading">#</a></h2><p>Reinforcement Learning (RL) is usually applied for state of the art AI research and often make the headlines. Yet it still fails to deliver on concrete business topics. At Ekimetrics we strive to transfer AI innovations into the business world and Reinforcement Learning is a unbelievable playground to find disruptive solutions to complex real-world problems. In particular, there are many optimization problems that could be solved using RL.</p><p>The Traveling Salesman Problem (TSP) has been solved for many years and used for tons of real-life situations including <strong>optimizing deliveries</strong> or <strong>network routing</strong>. This article will show a simple framework to <strong>apply Q-Learning to solving the TSP</strong>, and discuss the pros &amp; cons with other optimization techniques. It&#x27;s a perfect introduction for beginners in Reinforcement Learning and does not require heavy computational capabilities.</p><blockquote><p>You can find all the code open sourced <a href="https://github.com/TheoLvs/reinforcement-learning/tree/master/5.%20Delivery%20Optimization" target="_blank" rel="noopener noreferrer">here on Github</a></p></blockquote><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="the-traveling-salesman-problem"></a>The Traveling Salesman Problem<a class="hash-link" href="#the-traveling-salesman-problem" title="Direct link to heading">#</a></h2><p><img src="/assets/images/tsp_example-a3af33433166558228c6bd765c1aeb5e.png">
The Traveling Salesman Problem (or TSP) is a typical optimization problem, where one has to find the shortest route to visit different cities. There are many different ways to solve this problem using discrete optimization techniques. </p><p>Like many optimization problems, it&#x27;s a NP-hard problem, which in short means that it&#x27;s easy (in terms of speed) to solve for 5 cities, already impossible to brute force for 50. And almost impossible for most algorithms for  5,000 cities. Even for 15 cities, it&#x27;s already 1 trillion permutations to compute (15!), there are optimization techniques that are more adequate : dynamic programming, branch and bound algorithms, nearest neighbors approximations, or ant colonies optimizations.</p><p>Furthermore, the problem described here is too simple to describe a real-life delivery situation. It does not take into account multiple vehicle fleet, electric vehicle charging, time window constraints, capacity constraints, aleatory perturbations, etc... Hence, each variant of the TSP has its own optimization frameworks (in terms of variables and constriants), and the more you complexify the problem, the more difficult it is of course. That&#x27;s why in practice delivery companies use combinations of those variants coupled with heuristics. The most advanced companies today add Machine Learning techniques on top of those algorithms, in particular to replace manual heuristics and better estimate in-context durations.    </p><p>In Python, the easiest way to get started with TSP and its variants is probably the great open source library <a href="https://developers.google.com/optimization/routing" target="_blank" rel="noopener noreferrer">OR-Tools by Google</a>. And if you want to learn more about discrete optimization, I can only recommend the great MOOC on <em>Discrete Optimization by the University of Melbourne</em> you can find on <a href="https://www.coursera.org/learn/discrete-optimization" target="_blank" rel="noopener noreferrer">Coursera</a>. </p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="applying-reinforcement-learning-to-the-tsp"></a>Applying Reinforcement Learning to the TSP<a class="hash-link" href="#applying-reinforcement-learning-to-the-tsp" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="why-bother-using-reinforcement-learning"></a>Why bother using Reinforcement Learning?<a class="hash-link" href="#why-bother-using-reinforcement-learning" title="Direct link to heading">#</a></h3><p>If it&#x27;s already solved by classical optimization techniques, why bother using Reinforcement Learning? Well several answers: </p><ul><li>It&#x27;s fun and I personally love practicing RL. Curiosity is a great driver for innovation, and here I was really wondering if it could be applied for such a problem.</li><li>RL is rarely used in real-life problems. Playing games or manipulating robot hands is awesome, but when it comes to business problems, RL often fails compared to simple heuristics or algorithms. At Ekimetrics, we always look for applying state-of-the-art AI research to the business problems we encounter in the real-world. </li></ul><p>However, Reinforcement Learning (in theory) would hold many advantages compared to classical optimization techniques : </p><ul><li><strong>Offering a general framework for all problems</strong>, indeed instead of tweaking the constraints and defining extra variables, you can change the reward, and defining a multi agent problem if needed for fleet optimization. Adding extra information like delivery time estimation is also eased if you can integrate the prediction algorithm with a similar ML techniques (e.g. Neural Networks)</li><li><strong>Having a &quot;live&quot; decision making algorithm</strong>. Because you would train a RL alorithm by making the next delivery decision at each stop, compared to &quot;offline&quot; optimization algorithms that study the problem with no unknowns, you inherently would be able to take different decisions if something happened during the experience, whereas you would need to recalculate with classical techniques</li><li><strong>Being robust to unknowns and aleatory perturbations</strong></li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="transforming-the-tsp-to-a-rl-problem"></a>Transforming the TSP to a RL problem<a class="hash-link" href="#transforming-the-tsp-to-a-rl-problem" title="Direct link to heading">#</a></h3><p>Before jumping into the TSP variants, let&#x27;s take the most simplest version: <em>a delivery man who has to deliver 50 packages</em>. Between each stop can be defined a distance or a duration (or a more complex metric). </p><p>To transform it to a RL problem, we need to define: </p><ul><li><strong>Agent</strong>: the delivery man</li><li><strong>Environment</strong>: the different packages to deliver (and their destination) and the city where to navigate</li><li><strong>States</strong>: the location where the delivery guy currently stops </li><li><strong>Actions</strong>: at each location, the decisions to make (modeled as a Markov process) are: &quot;where to go next&quot; (or &quot;which location do I chose next&quot;)</li><li><strong>Reward</strong>: Between two locations (states), how long (or how far) it is</li></ul><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="creating-the-routing-environment"></a>Creating the routing environment<a class="hash-link" href="#creating-the-routing-environment" title="Direct link to heading">#</a></h3><p>Creating a simple version of the environment is quite simple in pure Python. Indeed, you can store the position of the stops in a 2D virtual world as a numpy array or a Pandas DataFrame. Distances between stops can be calculated with an euclidean distance, but it could be complexified to account for durations or represent any distance/duration metric you would see in a routing network. </p><p><img src="/assets/images/env2-8887c8a80fd93eab07028f70b2a38dc3.png"></p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#F8F8F2;background-color:#282A36"><div class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> scipy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spatial</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">distance </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> cdist</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">ENV_SIZE </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">10</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">N_STOPS </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">100</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Creating the stops using numpy random points generator</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">xy </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">random</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">rand</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">N_STOPS</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token number">2</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token operator">*</span><span class="token plain">ENV_SIZE</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Computing the distances between each points</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># Here use euclidean distances, but any metric would do</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain"></span><span class="token comment" style="color:rgb(98, 114, 164)"># This distance matrix can actually represent a time, a distance or something else</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">distance_matrix </span><span class="token operator">=</span><span class="token plain"> cdist</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>Then we want to define the starting position, the route, and the end position. Meaning that if we have to traverse A, B, C, D, E, possible routes would be for example <code>A-&gt;C-&gt;B-&gt;E-&gt;D</code> or <code>B-&gt;D-&gt;E-&gt;C-&gt;A</code>. </p><p>By the way with 5 stops you have 5! possible routes or 120 possible routes. For 10 stops you already have 3.6 million possible routes. For 100 stops it&#x27;s 10 to the 158th power routes. It&#x27;s called the combinatory explosion, and that explains why this simple problem is impossible to brute force for a high number of stops. </p><p>We can visualize routes by drawing lines between each stop</p><p><img src="/assets/images/env1-ce256f64cdffdbd7e5143d792d7867ad.png"></p><p>We can also already imagine more complex and realistic situations. For example, one experiment I wanted to do was to stress test the RL algorithm to aleatory events. For example a known environment with unknown perturbations, like traffic. To model this interaction, we add a &quot;traffic zone&quot; inside our environment, where routes are much slower if taken. To account for the extra duration, we calculate the intersection points of the route within the &quot;traffic zone&quot; and measure the distance of the formed segment, we then use that distance weighed with a traffic intensity factor. </p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-undefined codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#F8F8F2;background-color:#282A36"><div class="token-line" style="color:#F8F8F2"><span class="token plain">i1,i2 = intersections</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">distance_traffic = np.sqrt((i2[1]-i1[1])**2 + (i2[0]-i1[0])**2)</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">additional_reward = distance_traffic * traffic_intensity * np.random.rand()</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p><img src="data:image/png;base64,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"></p><p>Now that we have the overal idea, we have to design an environment object in Python to be fed to a Reinforcement Learning agent. We use the typical design framework inspired from OpenAI Gym:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#F8F8F2;background-color:#282A36"><div class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">DeliveryEnvironment</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">reset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;Restart the environment for experience replay</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        Returns the first state</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        &quot;&quot;&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">pass</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">step</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;Takes an action in a given state</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        Returns:</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">            s_next: the next state</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">            reward: the reward for such action</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">            done: if the simulation is done</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        &quot;&quot;&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">pass</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">render</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">&quot;&quot;&quot;Visualize the environment state</span></div><div class="token-line" style="color:#F8F8F2"><span class="token triple-quoted-string string" style="color:rgb(255, 121, 198)">        &quot;&quot;&quot;</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">pass</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="designing-the-q-learning-algorithm"></a>Designing the Q-Learning algorithm<a class="hash-link" href="#designing-the-q-learning-algorithm" title="Direct link to heading">#</a></h3><p>Before jumping into complex Deep Learning, I wondered if a simple <strong>Q-Learning framework would work</strong>. Basically with Q-Learning you want to evaluate a matrix mapping states, actions and rewards. Indeed to make a decision in a given state about the best actions to do, you would love to have an estimate if the decision was the best in the long term. This is represented by the Q values. </p><p>In our case, the rows are the different states (all the stops) and the columns the possible actions to take in this state, hence the next stop to go. The values are the estimated long-term reward you would get by taking this action. So, if you are found in a state A, you would like to take the action with the maximum Q value. </p><p>For our TSP problem for example, we would have a Q-Matrix of 50 by 50 if we have 50 stops. </p><p>Because we want to inform the routing algorithm with as much unbiased data we can find, we can actually initalize the Q matrix (also called Value function because it maps out states and actions to rewards - the values) with the distance matrix between all stops. Indeed, if you would not consider a long-term decision making strategy, you would apply a greedy one where you would chose the closest stop as a next destination. Yet it would definetely be better than random. </p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#F8F8F2;background-color:#282A36"><div class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">from</span><span class="token plain"> scipy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">spatial</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">distance </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">import</span><span class="token plain"> cdist</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">Q </span><span class="token operator">=</span><span class="token plain"> cdist</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">xy</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>Ok, but how to update those values and incorporate long-term planning? This is exactly the goal of the Q-Learning algorithm.
Imagine you are delivering pizzas every day all across the city, you have an old GPS to help you decide the shortest route between your stops. But your city is much more complicated than what you and your GPS know. What would happen? </p><ul><li>The first day, you would chose the closest stop first and then jump to the next closest one. You will quickly realize that it&#x27;s not optimized. You should maybe have gone first to another neighborhood and deliver everything in the area before jumping to another one. </li><li>So the next day, you commit to another strategy, armed with yesterday&#x27;s experience. Definitely, looking ahead and avoiding single deliveries in remote areas even if they are closest is a better idea. But while you are exploring the best routes, you pass through the city center and get blocked into traffic that terribly slows you down. </li><li>The 3rd day, you will try to apply the same general strategy, but definitely if possible you will never go through the city center, and try circling around the city to save some precious time. </li></ul><p>This <strong>trial-and-error behavior is basically how experience replay works in the Reinforcement Learning framework</strong>. </p><p>If we code an agent abstraction, it could look like this:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#F8F8F2;background-color:#282A36"><div class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">class</span><span class="token plain"> </span><span class="token class-name">QAgent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">Agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">__init__</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">epsilon </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1.0</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    epsilon_min </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.01</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">epsilon_decay </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.999</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">gamma </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.95</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">lr </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0.8</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">states_size </span><span class="token operator">=</span><span class="token plain"> states_size</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">actions_size </span><span class="token operator">=</span><span class="token plain"> actions_size</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon </span><span class="token operator">=</span><span class="token plain"> epsilon</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_min </span><span class="token operator">=</span><span class="token plain"> epsilon_min</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_decay </span><span class="token operator">=</span><span class="token plain"> epsilon_decay</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gamma </span><span class="token operator">=</span><span class="token plain"> gamma</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">lr </span><span class="token operator">=</span><span class="token plain"> lr</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">build_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">build_model</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        Q </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">zeros</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">states_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> Q</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">lr </span><span class="token operator">*</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">r </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gamma</span><span class="token operator">*</span><span class="token plain">np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">max</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">-</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon </span><span class="token operator">&gt;</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_min</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">            self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon </span><span class="token operator">*=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon_decay</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">act</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        q </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">random</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">rand</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">&gt;</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">epsilon</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">            a </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">argmax</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">else</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">            a </span><span class="token operator">=</span><span class="token plain"> np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">random</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">randint</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">actions_size</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> a</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>The most important line is this one:</p><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#F8F8F2;background-color:#282A36"><div class="token-line" style="color:#F8F8F2"><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">=</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token plain"> </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">lr </span><span class="token operator">*</span><span class="token plain"> </span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">r </span><span class="token operator">+</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">gamma</span><span class="token operator">*</span><span class="token plain">np</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token builtin" style="color:rgb(189, 147, 249)">max</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"> </span><span class="token operator">-</span><span class="token plain"> self</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">Q</span><span class="token punctuation" style="color:rgb(248, 248, 242)">[</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">]</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><p>This is the update rule in basic Q-Learning, where you increment the Q-value for each action in each experience replay (simulating a day of delivery hundreds of time) by the current reward + the reward for the best possible action you would take in the future. This recursive equation is a variation of the famous Bellman equation for Q value functions. </p><p>Notice two factors: </p><ul><li>The learning rate <code>lr</code> control the learning speed (like in Deep Learning)</li><li>The gamma factor <code>gamma</code> is the discount factor, and control long-term planning. Indeed if gamma = 0, you will only get the next action reward (your agent is &quot;short sighted&quot; only seeking current rewards), if gamma = 1 you will be more oriented towards the future rewards (above 1 it may diverge)</li></ul><p>Those two factors are our most important hyperparameters to tune during training (there are others like the epsilon variables defined in the initialization, if you are curious take a look at epsilon-greedy methods, a super simple way of tackling the exploration-exploitation dilemma in Reinforcement Learning)</p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="writing-the-training-loop"></a>Writing the training loop<a class="hash-link" href="#writing-the-training-loop" title="Direct link to heading">#</a></h3><p>Once we have define the environment, the Q-Agent and the update rules for the value function, we only need the final step: the training loop. We will apply <strong>experience replay</strong> to our poor delivery guy stucked in an infinite time loop. </p><p><img src="/assets/images/drstrange-9a522bfeff0b9cdcc50a5ba4c85f8c2f.gif"> </p><p>Every day, over and over, he will try to deliver our 50 packages, find the best routes and do it all over the next day. In Reinforcement Learning we call each day an <strong>episode</strong>, where we simply:</p><ul><li>Reset the environment</li><li>Make a decision of the next state to go to</li><li>Remember the reward gained by this decision (minimum duration or distance elapsed)</li><li>Train our agent with this knowledge</li><li>Make the next decision until all stops are traversed</li></ul><div class="mdxCodeBlock_1zKU"><div class="codeBlockContent_actS"><div tabindex="0" class="prism-code language-python codeBlock_tuNs thin-scrollbar"><div class="codeBlockLines_3uvA" style="color:#F8F8F2;background-color:#282A36"><div class="token-line" style="color:#F8F8F2"><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">def</span><span class="token plain"> </span><span class="token function" style="color:rgb(80, 250, 123)">run_episode</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">verbose </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">1</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    s </span><span class="token operator">=</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reset</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">reset_memory</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    max_step </span><span class="token operator">=</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">n_stops</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    episode_reward </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    i </span><span class="token operator">=</span><span class="token plain"> </span><span class="token number">0</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">while</span><span class="token plain"> i </span><span class="token operator">&lt;</span><span class="token plain"> max_step</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Remember the states</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">remember_state</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Choose an action</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        a </span><span class="token operator">=</span><span class="token plain"> agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">act</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Take the action, and get the reward from environment</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">done </span><span class="token operator">=</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">step</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block">
</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Tweak the reward</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        r </span><span class="token operator">=</span><span class="token plain"> </span><span class="token operator">-</span><span class="token number">1</span><span class="token plain"> </span><span class="token operator">*</span><span class="token plain"> r</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> verbose</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"> </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">print</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">done</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Update our knowledge in the Q-table</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">.</span><span class="token plain">train</span><span class="token punctuation" style="color:rgb(248, 248, 242)">(</span><span class="token plain">s</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">a</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">r</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">s_next</span><span class="token punctuation" style="color:rgb(248, 248, 242)">)</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># Update the caches</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        episode_reward </span><span class="token operator">+=</span><span class="token plain"> r</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        s </span><span class="token operator">=</span><span class="token plain"> s_next</span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token comment" style="color:rgb(98, 114, 164)"># If the episode is terminated</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        i </span><span class="token operator">+=</span><span class="token plain"> </span><span class="token number">1</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">        </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">if</span><span class="token plain"> done</span><span class="token punctuation" style="color:rgb(248, 248, 242)">:</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">            </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">break</span><span class="token plain"></span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">            </span></div><div class="token-line" style="color:#F8F8F2"><span class="token plain">    </span><span class="token keyword" style="color:rgb(189, 147, 249);font-style:italic">return</span><span class="token plain"> env</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">agent</span><span class="token punctuation" style="color:rgb(248, 248, 242)">,</span><span class="token plain">episode_reward</span></div></div></div><button type="button" aria-label="Copy code to clipboard" class="copyButton_2GIj">Copy</button></div></div><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="results"></a>Results<a class="hash-link" href="#results" title="Direct link to heading">#</a></h2><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="q-learning-for-a-simple-tsp"></a>Q-Learning for a simple TSP<a class="hash-link" href="#q-learning-for-a-simple-tsp" title="Direct link to heading">#</a></h3><p>When you start training and experiencing the same problem overtime, your agent learns about the environment, this is shown by the episode rewards values for each experience replay. </p><p><img src="/assets/images/training-31d61ed9f6a9a6693dd40a6c4dfe151e.png"></p><ul><li>In the first phase, until the 400th episode, you are still exploring the different routes. Indeed with the epsilon decay method (with <code>epsilon_decay=0.999</code>), you are taking random actions at each step. </li><li>In the second phase, epsilon is lowering, and you start exploiting what you have learnt, and take less and less random actions to be more driven by Q values. </li></ul><p>What&#x27;s tricky with epsilon-greedy methods, is that it kind of forces of the convergence. So did it work? Let&#x27;s see. </p><h5><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="50-stops-experiment"></a>50 stops experiment<a class="hash-link" href="#50-stops-experiment" title="Direct link to heading">#</a></h5><p><img src="/assets/images/training_50_stops-f0073a10e627a6f50a17b55a2c32eeac.gif"></p><h5><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="100-stops-experiment"></a>100 stops experiment<a class="hash-link" href="#100-stops-experiment" title="Direct link to heading">#</a></h5><p><img src="/assets/images/training_100_stops-af172053854703e0125a1b6bf4fe81f8.gif"></p><h5><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="500-stops-experiment"></a>500 stops experiment<a class="hash-link" href="#500-stops-experiment" title="Direct link to heading">#</a></h5><p><img src="/assets/images/training_500_stops-3529ca589990add491164cb5925bfd81.gif"></p><p>In each experiment, the algorithm converges quite fast to a seamingly acceptable route. After exploring a lot of options it not only gives one route but variations of the accepted strategy, which can already be interesting to find alternatives. </p><h3><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="q-learning-for-a-tsp-with-traffic-zones"></a>Q-Learning for a TSP with traffic zones<a class="hash-link" href="#q-learning-for-a-tsp-with-traffic-zones" title="Direct link to heading">#</a></h3><p>Now that we have our environment, agent and framework defined, what&#x27;s great with RL is that we don&#x27;t have to change anything but the reward to model a different situation. Indeed because we tweaked the reward when you drove through a traffic zone, the agent will learn the same way to optimize his holistic route. </p><h5><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="100-stops-experiment-with-traffic-zones"></a>100 stops experiment with traffic zones<a class="hash-link" href="#100-stops-experiment-with-traffic-zones" title="Direct link to heading">#</a></h5><p><img src="/assets/images/training_100_stops_traffic-2f1b2933055b3023670ec5f1e577afad.gif"></p><p>Eureka, the agent will avoid as much as possible the traffic zones</p><h5><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="500-stops-experiment-with-traffic-zones"></a>500 stops experiment with traffic zones<a class="hash-link" href="#500-stops-experiment-with-traffic-zones" title="Direct link to heading">#</a></h5><p><img src="/assets/images/training_500_stops_traffic-0467ef757724ee8f0377f56c6f8b7b14.gif"></p><p>With more points, it&#x27;s even more interesting, the agent will really circle around the traffic zone and prefer longer but faster routes. </p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="next-steps"></a>Next steps<a class="hash-link" href="#next-steps" title="Direct link to heading">#</a></h2><p>I hope this simple experiment has highlighted how to apply (non-Deep Learning) Reinforcement Learning techniques to real-life problems. I haven&#x27;t had time to benchmark the resolution against other optimization techniques (which I should have done I confess), but let&#x27;s try to draw some pros and cons for the approach. </p><h5><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="-cons"></a>⛔ Cons:<a class="hash-link" href="#-cons" title="Direct link to heading">#</a></h5><ul><li>Probably slower</li><li>Definitely less accurate than a discrete optimization technique</li></ul><h5><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="-pros"></a>✅ Pros:<a class="hash-link" href="#-pros" title="Direct link to heading">#</a></h5><ul><li>General framework to be updated in real-life situations (eg: the traffic) and extended to more complex problems</li><li>Alternative routes are proposed</li><li>&quot;Online&quot; decision making (meaning that you have an algorithm armed with a next-best decision recommendation system)</li></ul><p>Next steps is to extend the work to an even more global framework to account for multiple vehicle fleets, charging stations and more. The latter idea will require to use Deep Reinforcement Learning because states could not be represented as a matrix, and will probably be more difficult (impossible?) to train, but that&#x27;s a topic for a next article!  </p><h2><a aria-hidden="true" tabindex="-1" class="anchor enhancedAnchor_prK2" id="references"></a>References<a class="hash-link" href="#references" title="Direct link to heading">#</a></h2><ul><li>All the code is open sourced <a href="https://github.com/TheoLvs/reinforcement-learning/tree/master/5.%20Delivery%20Optimization" target="_blank" rel="noopener noreferrer">here</a> on Github</li><li>OR-Tools <a href="https://developers.google.com/optimization/routing" target="_blank" rel="noopener noreferrer">open source library</a> by Google</li><li>MOOC on <a href="https://www.coursera.org/learn/discrete-optimization" target="_blank" rel="noopener noreferrer">discrete optimization</a> by the University of Melbourne on Coursera</li><li>The timeless <a href="https://www.youtube.com/watch?v=2pWv7GOvuf0&amp;ab_channel=DeepMind" target="_blank" rel="noopener noreferrer">MOOC on Reinforcement Learning</a> by David Silver at Deepmind</li></ul></section><footer class="row margin-vert--lg"><div class="col"><strong>Tags:</strong><a class="margin-horiz--sm" href="/blog/tags/reinforcement-learning">Reinforcement Learning</a><a class="margin-horiz--sm" href="/blog/tags/logistics">Logistics</a></div></footer></article><div class="margin-vert--xl"><nav class="pagination-nav" aria-label="Blog post page navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/blog/introduction-pyepidemics"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">« Introduction to Pyepidemics - epidemiological modeling in Python</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/blog/dash-deployment"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Deploying a Python Dash application for beginners »</div></a></div></nav></div></main><div class="col col--2"><div class="tableOfContents_2xL- thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#summary" class="table-of-contents__link">Summary</a></li><li><a href="#the-traveling-salesman-problem" class="table-of-contents__link">The Traveling Salesman Problem</a></li><li><a href="#applying-reinforcement-learning-to-the-tsp" class="table-of-contents__link">Applying Reinforcement Learning to the TSP</a><ul><li><a href="#why-bother-using-reinforcement-learning" class="table-of-contents__link">Why bother using Reinforcement Learning?</a></li><li><a href="#transforming-the-tsp-to-a-rl-problem" class="table-of-contents__link">Transforming the TSP to a RL problem</a></li><li><a href="#creating-the-routing-environment" class="table-of-contents__link">Creating the routing environment</a></li><li><a href="#designing-the-q-learning-algorithm" class="table-of-contents__link">Designing the Q-Learning algorithm</a></li><li><a href="#writing-the-training-loop" class="table-of-contents__link">Writing the training loop</a></li></ul></li><li><a href="#results" class="table-of-contents__link">Results</a><ul><li><a href="#q-learning-for-a-simple-tsp" class="table-of-contents__link">Q-Learning for a simple TSP</a></li><li><a href="#q-learning-for-a-tsp-with-traffic-zones" class="table-of-contents__link">Q-Learning for a TSP with traffic zones</a></li></ul></li><li><a href="#next-steps" class="table-of-contents__link">Next steps</a></li><li><a href="#references" class="table-of-contents__link">References</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container"><div class="row footer__links"><div class="col footer__col"><h4 class="footer__title">About us</h4><ul class="footer__items"><li class="footer__item"><a href="https://ekimetrics.com/who-we-are/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Who we are ?</a></li><li class="footer__item"><a href="https://ekimetrics.com/our-team/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Our team</a></li><li class="footer__item"><a href="https://ekimetrics.us13.list-manage.com/subscribe?u=85b8ce42caa0a733e98233bc4&amp;id=6355d0a6f9" target="_blank" rel="noopener noreferrer" class="footer__link-item">Subscribe to our newsletter</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Find us</h4><ul class="footer__items"><li class="footer__item"><a href="https://github.com/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github</a></li><li class="footer__item"><a href="https://ekimetrics.com/careers/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Careers</a></li><li class="footer__item"><a href="https://www.welcometothejungle.com/fr/companies/ekimetrics" target="_blank" rel="noopener noreferrer" class="footer__link-item">Eki on Welcome to the jungle</a></li></ul></div><div class="col footer__col"><h4 class="footer__title">Contact</h4><ul class="footer__items"><li class="footer__item"><a href="mailto:inno@ekimetrics.com" target="_blank" rel="noopener noreferrer" class="footer__link-item">Get in touch with our teams</a></li></ul></div></div><div class="footer__bottom text--center"></div></div></footer></div>
<script src="/styles.e35008ef.js"></script>
<script src="/runtime~main.9e97a696.js"></script>
<script src="/main.792963b8.js"></script>
<script src="/1.11b8b369.js"></script>
<script src="/2.2d4efa6a.js"></script>
<script src="/108.db740e28.js"></script>
<script src="/01a85c17.cf0f7590.js"></script>
<script src="/1be78505.a54828de.js"></script>
<script src="/6442c0a2.954850d5.js"></script>
<script src="/6875c492.91e21155.js"></script>
<script src="/a6aa9e1f.8f6293d7.js"></script>
<script src="/bb9d1367.6cb11fe8.js"></script>
<script src="/ccc49370.d52064ed.js"></script>
<script src="/db8a5f2c.32a992fa.js"></script>
<script src="/111.e6761f52.js"></script>
<script src="/ece8ad2d.23c964c5.js"></script>
<script src="/c4f5d8e4.904556d1.js"></script>
<script src="/2e4ccabb.01f0e56c.js"></script>
</body>
</html>